{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameworkModel():\n",
    "    def __init__(self):\n",
    "        self.pre_prompt = \"\"\"We are in the situation of a case interview for applying to a job in consulting. You are taking the role of the interviewer in this case. You are there to practice solving case studies with the interviewee. You are provided with a reference solution to the case. You are not tasked to solve the case yourself but rather guide the candidate throughout the case. Important things for you to remember\n",
    "            \\n - You are supposed to help the candidate but not provide with with the solutions. The candidate must be able to solve the case on its own.\n",
    "            \\n - The candidate must not match the reference solution one to one but should provide most information.\n",
    "            \\n - after each step wait for the candidate to answer the question. You are never to take the role of the candidate and answer questions yourself!\n",
    "            \\n - Never automatically add something to the responses of the candidate. Only react towards what the candidate is writing.\n",
    "            \\n - You are provided with the full history of the conversation after the # Case Interview tag. Tags are used to show who said what in the conversation. Possible tags are 1) Candidate: 2) Interviewer: 3) Command: 4) State:\n",
    "            \\n - You are only supposed to use the Interviewer or System tag. Use the Interviewer tag whenever you are talking to the Candidate. Ocasionally a Command will be used to ask you about the current interview state (example: Command: Which section of the interview are we currenlty in?). Use the State tag to respond to these commands.\n",
    "            \\n - Command: and State: tags are not shown to the candidate\n",
    "            \\n - The command tag is used to provide additional commands to you. Pay attention to these commands when continuing the conversation. \n",
    "            \"\"\"\n",
    "        \n",
    "        self.task_specific_prompt = \"\"\"\n",
    "            Your task is to guide the candidate through one section of the case interview process. The specific section you are evaluating is the development of a framework for the case. Your tasks are:\n",
    "            \\n - Guide the candidate through developing a framework for the case\n",
    "            \\n - First the candidate should take some time to come up with a framework on their own. \n",
    "            \\n - A good framework should consists of 2-4 buckets. The buckets should be mutually exclusive but in total cover all important aspects of the case.\n",
    "            \\n - The candidate should not just provide the buckets but more information what exactly he wants to tackle exactly within each bucket\n",
    "            \\n - You are given a reference solution below. The candidate must not match the reference solution one to one but should provide most information. It is your task to evaluate if the candidate has given enough information.\n",
    "            \\n - If the candidate misses some points in his framework, ask him if he wants to add something to his framework. You can provide tips to the candidate if he is stuck.\n",
    "            \\n - It is your task to check if the candidate has finished this section and came up with a good enough framework. Do not let the candidate leave before this is achieved.\"\"\"\n",
    "\n",
    "        self.case_information = \"\"\"# Reference Information about the case\n",
    "            \\n ## Problem Statement: A leading biotech company is developing a treatment for Alzheimer's disease. This ground-breaking treatment is different from any other Alzheimer's treatment on the market because it actually slows the progression of the disease, rather than just treating its symptoms. The company’s executive team is concerned about the results of a high-level internal feasibility study that flagged a potential risk to the launch of this treatment – a rumored shortage of infusion capacity in the US. Given that the Alzheimer's treatment is designed to be administered via infusion, such a shortage would severely hamper the market acceptance and hence the financial rewards from the treatment. In preparation for the launch of this treatment, the company has hired you to help them figure out the extent of the expected shortfall, and how they should respond.\n",
    "            \\n ## Additional Information:  [\n",
    "                \"Infusion refers to inserting the medicine directly into a patients bloodstream via IV (intravenous) application, ideally through the patient’s arm.\",\n",
    "                \"The treatment will be launched in the US alone.\",\n",
    "                \"The client has not yet estimated how big the infusion shortfall will be.\",\n",
    "                \"The client does not have any strategies to mitigate the shortfall.\",\n",
    "                \"Most other Alzheimers medications are delivered as oral pills.\",\n",
    "                \"The treatment (if approved by the FDA) would come to market in about 2 years.\"\n",
    "            ]\"\"\"\n",
    "        \n",
    "        self.reference_solution = \"\"\"# Reference Solution for good framework\n",
    "            \\n - Bucket 1: What is the expected shortfall in infusion capacity?\n",
    "            \\n - Bucket 2: Why is there a shortfall in infusion capacity?\n",
    "            \\n - Bucket 3: How can the shortfall in infusion capacity be mitigated?\"\"\"\n",
    "        \n",
    "        self.conversation_history = [self.pre_prompt, self.task_specific_prompt, self.case_information, self.reference_solution]\n",
    "\n",
    "        self.llm = OpenAI()\n",
    "    \n",
    "    def run_llm(self):\n",
    "        return self.llm(\"\\n\\n\".join(self.conversation_history))\n",
    "    \n",
    "    def add_candidate_interaction(self, candidate_response, on_finished_callback):\n",
    "        self.conversation_history.append(f\"Candidate: {candidate_response}\")\n",
    "        # check whether we continued\n",
    "        self.conversation_history.append(\"Command: Did the candidate provide enough information to solve the case. Be critical. Especially check if enough buckets are provided and if detailed information per bucket is provided, it is not enough to just state the buckets. Answer with either State: Enough information provided or State: Not enough information provided\")\n",
    "\n",
    "        result = self.run_llm()\n",
    "        print(f\"Check to continue result: {result}\")\n",
    "\n",
    "        # check how to continue\n",
    "        if \"State: Not enough information provided\".lower() in result.lower():\n",
    "            print(\"Not enough information provided\")\n",
    "            self.conversation_history.append(\"Command: The candidate has not provided enough information. Ask the candidate to add more information to his framework. You can provide tips to the candidate if he is stuck.\")\n",
    "            \n",
    "            result = self.run_llm()\n",
    "\n",
    "            print(result)\n",
    "        \n",
    "        elif \"State: Enough information provided\".lower() in result.lower():\n",
    "            print(\"Enough information provided\")\n",
    "            self.conversation_history.append(\"Command: The candidate has provided enough information. You can now ask the candidate to move on to the next section, ask him where he wants to start\")\n",
    "            result = self.run_llm()\n",
    "            on_finished_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check to continue result: \n",
      "\n",
      "State: Not enough information provided.\n",
      "Not enough information provided\n",
      "\n",
      "\n",
      "Interviewer: That's a great start, but can you provide more detail in each bucket? What are some of the specific questions you plan to answer in each bucket? Can you think of any other buckets that could help you answer the problem statement?\n",
      "Check to continue result: \n",
      "\n",
      "State: Not enough information provided\n",
      "Not enough information provided\n",
      "\n",
      "\n",
      "Interviewer: That's a great start. What else do you think you should include in your framework to ensure you have a comprehensive approach to solving the case?\n",
      "Check to continue result: \n",
      "\n",
      "State: Enough information provided\n",
      "Enough information provided\n",
      " or provide additional information.\n"
     ]
    }
   ],
   "source": [
    "framework_model = FrameworkModel()\n",
    "framework_model.add_candidate_interaction(\"I would like to structure my case into two buckets. Bucket 1: I want to understand the shortfall in infusion capacity. Bucket 2: I want to come up with mitigation strategies for the shortfall in infusion capacity.\")\n",
    "\n",
    "framework_model.add_candidate_interaction(\"Sure in the first buckets I think it would be intersting how much infusion capacity there is at the moment and how much infusion capacity we require\")\n",
    "\n",
    "framework_model.add_candidate_interaction(\"Yep of course. In the second bucket it might be interesting to check if it is more a skill issue. Or for example an infrastructure issue. Maybe also the incentives are wrong because service providers are not paid enough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "State: Not enough information provided\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"Candidate: Candidate: I would like to structure my case into two buckets. Bucket 1: I want to understand the shortfall in infusion capacity. Bucket 2: I want to come up with mitigation strategies for the shortfall in infusion capacity.\"\n",
    "prompt2 = \"Command: Did the candidate provide enough information to solve the case. Be critical. Especially check if enough buckts are provided and if detailed information per bucket is provided, it is not enough to just state the buckets. Answer with either State: Enough Information provided or State: Not enough information provided\"\n",
    "conversation = [pre_prompt, task_specific_prompt, prompt1, prompt2]\n",
    "\n",
    "response = llm(\"\\n\\n\".join(conversation))\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"Command: The candidate did not provide eonugh information. Continue the conversation. If the candidate is missing buckets tell him about this. If he is missing information per bucket ask him to provide more information\"\n",
    "conversation.append(response)\n",
    "conversation.append(prompt)\n",
    "\n",
    "response = llm(\"\\n\\n\".join(conversation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Interviewer: That's a great start. Have you thought about what kind of information you would need to answer the questions for each bucket? For example, in Bucket 1, what information do you need to figure out the expected shortfall in infusion capacity?\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_for_datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
